{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous plots\n",
    "\n",
    "This notebook contains miscellaneous plots I used to present tree based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import datasets\n",
    "import pydotplus\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# used to display trees\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xi = np.arange(0,51,1)\n",
    "\n",
    "# exponential that converges to 1\n",
    "yi = 1-np.exp(-0.05*xi)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(xi, 0.3*yi+0.2, lw=4, label='Weak learner')\n",
    "plt.plot(xi, -0.15*yi+0.2, lw=4, label='Overall ensemble')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.yticks([0, 0.5], fontsize=24)\n",
    "plt.xticks(np.arange(0,51,10), fontsize=24)\n",
    "\n",
    "# add text\n",
    "plt.arrow(20, 0.3, -10, 0, width=0.005, head_length=1, color='k')\n",
    "plt.text(20.5, 0.3, 'Each tree has higher error', fontsize=24, va='center')\n",
    "\n",
    "plt.arrow(20, 0.15, -10, 0, width=0.005, head_length=1, color='k')\n",
    "plt.text(20.5, 0.15, 'Ensemble has lower error', fontsize=24, va='center')\n",
    "plt.ylabel('Error', fontsize=24)\n",
    "plt.xlabel('Number of trees', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_colormap(seq):\n",
    "    \"\"\"Return a LinearSegmentedColormap\n",
    "    seq: a sequence of floats and RGB-tuples. The floats should be increasing\n",
    "    and in the interval (0,1).\n",
    "    \"\"\"\n",
    "    seq = [(None,) * 3, 0.0] + list(seq) + [1.0, (None,) * 3]\n",
    "    cdict = {'red': [], 'green': [], 'blue': []}\n",
    "    for i, item in enumerate(seq):\n",
    "        if isinstance(item, float):\n",
    "            r1, g1, b1 = seq[i - 1]\n",
    "            r2, g2, b2 = seq[i + 1]\n",
    "            cdict['red'].append([item, r1, r2])\n",
    "            cdict['green'].append([item, g1, g2])\n",
    "            cdict['blue'].append([item, b1, b2])\n",
    "    return matplotlib.colors.LinearSegmentedColormap('CustomMap', cdict)\n",
    "\n",
    "# OLD PURPLE colormap\n",
    "\n",
    "# colormap\n",
    "#cm = plt.cm.get_cmap(name='Purples',lut=2) # dummy initialization\n",
    "#c1 = [x/256.0 for x in [224,236,244]]\n",
    "#c2 = [x/256.0 for x in [136,86,167]]\n",
    "#cm = cm.from_list('custom', [c1,c2], N=2)\n",
    "\n",
    "\n",
    "# NEW custom colormap\n",
    "#e58139f9 - orange\n",
    "#399de5e0 - to blue\n",
    "s = list()\n",
    "\n",
    "lo = np.array(matplotlib.colors.to_rgb('#e5813900'))\n",
    "hi = np.array(matplotlib.colors.to_rgb('#399de5e0'))\n",
    "\n",
    "for i in range(255):\n",
    "    s.append( list((hi-lo)*(float(i)/255)+lo) )\n",
    "cm = make_colormap(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_purple(mdl, X, y, feat):\n",
    "    plt.figure(figsize=[8,5])\n",
    "\n",
    "    # colormap\n",
    "    cm = plt.cm.get_cmap(name='Purples',lut=2) # dummy initialization\n",
    "    c1 = [x/256.0 for x in [224,236,244]]\n",
    "    c2 = [x/256.0 for x in [136,86,167]]\n",
    "    cm = cm.from_list('custom', [c1,c2], N=2)\n",
    "\n",
    "    # get minimum and maximum values\n",
    "    x0_min = X[:, 0].min()\n",
    "    x0_max = X[:, 0].max()\n",
    "    x1_min = X[:, 1].min()\n",
    "    x1_max = X[:, 1].max()\n",
    "\n",
    "    vmin = np.min([x0_min,x1_min])\n",
    "    vmax = np.max([x0_max,x1_max])\n",
    "    xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                         np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot the contour - colouring different regions\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cm, levels=[0,1,2])\n",
    "\n",
    "    # plot the individual data points - colouring by the *true* outcome\n",
    "    color = np.asarray(y.ravel(),dtype='float')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=color, marker='o',\n",
    "                s=60, cmap=cm)\n",
    "\n",
    "    plt.xlabel(feat[0],fontsize=24)\n",
    "    plt.ylabel(feat[1],fontsize=24)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    plt.colorbar(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_pred_2d_old(mdl, X, y, feat):\n",
    "    # look at the regions in a 2d plot\n",
    "    # based on scikit-learn tutorial plot_iris.html\n",
    "\n",
    "    # get minimum and maximum values\n",
    "    x0_min = X[:, 0].min()\n",
    "    x0_max = X[:, 0].max()\n",
    "    x1_min = X[:, 1].min()\n",
    "    x1_max = X[:, 1].max()\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                         np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot the contour - colouring different regions\n",
    "    cs = plt.contourf(xx, yy, Z, cmap='hsv')\n",
    "\n",
    "    # plot the individual data points - colouring by the *true* outcome\n",
    "    color = y.ravel()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=color, marker='o', s=40, cmap='Blues')\n",
    "\n",
    "    plt.xlabel(feat[0],fontsize=24)\n",
    "    plt.ylabel(feat[1],fontsize=24)\n",
    "    plt.axis(\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_pred_2d(mdl, X, y, feat, cm=None, plot_colorbar=True):\n",
    "    # look at the regions in a 2d plot\n",
    "    # based on scikit-learn tutorial plot_iris.html\n",
    "    \n",
    "    # get minimum and maximum values\n",
    "    x0_min = X[:, 0].min()\n",
    "    x0_max = X[:, 0].max()\n",
    "    x1_min = X[:, 1].min()\n",
    "    x1_max = X[:, 1].max()\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 100),\n",
    "                         np.linspace(x1_min, x1_max, 100))\n",
    "\n",
    "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    if not cm:\n",
    "        # custom colormap\n",
    "        #e58139f9 - orange\n",
    "        #399de5e0 - to blue\n",
    "        s = list()\n",
    "\n",
    "        lo = np.array(matplotlib.colors.to_rgb('#e5813900'))\n",
    "        hi = np.array(matplotlib.colors.to_rgb('#399de5e0'))\n",
    "\n",
    "        for i in range(255):\n",
    "            s.append( list((hi-lo)*(float(i)/255)+lo) )\n",
    "        cm = make_colormap(s)\n",
    "    \n",
    "    # plot the contour - colouring different regions\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "    # plot the individual data points - colouring by the *true* outcome\n",
    "    color = y.ravel()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k', linewidth=2,\n",
    "                marker='o', s=60, cmap=cm)\n",
    "\n",
    "    plt.xlabel(feat[0],fontsize=24)\n",
    "    plt.ylabel(feat[1],fontsize=24)\n",
    "    plt.axis(\"tight\")\n",
    "    if plot_colorbar:\n",
    "        #plt.clim([-1.5,1.5])\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# real example\n",
    "df = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple plot with just the points\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.scatter(0, 1, s=400)\n",
    "plt.scatter(0, 2,color=lo, s=400)\n",
    "plt.scatter(0, 3,color=hi, s=400)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 16 plots, 3 subplots per row and text\n",
    "f, ax = plt.subplots(4, 4, figsize=[16,10], sharex='col', sharey='row')\n",
    "\n",
    "# for this plot, we re-order the data so sepal length is bottom right\n",
    "data = df['data']\n",
    "data = data[:, ::-1]\n",
    "feat = df['feature_names']\n",
    "feat = feat[::-1]\n",
    "\n",
    "for i in range(df['data'].shape[1]):\n",
    "    for j in range(df['data'].shape[1]):\n",
    "        if i==j:\n",
    "            ax[i, j].grid()\n",
    "        else:\n",
    "            ax[i, j].scatter(data[:50,j], data[:50,i])\n",
    "            ax[i, j].scatter(data[50:100,j], data[50:100,i],color=lo)\n",
    "            ax[i, j].scatter(data[100:,j], data[100:,i],color=hi)\n",
    "            \n",
    "# add text to middle plots\n",
    "for i in range(df['data'].shape[1]):\n",
    "    xloc = ax[i,i].get_xlim()\n",
    "    yloc = ax[i,i].get_ylim()\n",
    "    ax[i, i].text(np.mean(xloc), np.mean(yloc), feat[i],\n",
    "                  horizontalalignment='center', verticalalignment='center', fontsize=16)\n",
    "    \n",
    "# hide x ticks for top plots\n",
    "plt.setp([a.get_xticklabels() for a in ax[0, :]], visible=False)\n",
    "\n",
    "# hide y ticks for right plots\n",
    "plt.setp([a.get_yticklabels() for a in ax[:, 1]], visible=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 16 plots, 3 subplots per row and text\n",
    "f, ax = plt.subplots(4, 4, figsize=[16,10], sharex='col', sharey='row')\n",
    "\n",
    "# for this plot, we re-order the data so sepal length is bottom right\n",
    "data = df['data']\n",
    "data = data[:, ::-1]\n",
    "feat = df['feature_names']\n",
    "feat = feat[::-1]\n",
    "\n",
    "for i in range(df['data'].shape[1]):\n",
    "    for j in range(df['data'].shape[1]):\n",
    "        if i==j:\n",
    "            ax[i, j].grid()\n",
    "        else:\n",
    "            #ax[i, j].scatter(data[:50,j], data[:50,i])\n",
    "            ax[i, j].scatter(data[50:100,j], data[50:100,i],color=lo)\n",
    "            ax[i, j].scatter(data[100:,j], data[100:,i],color=hi)\n",
    "            \n",
    "# add text to middle plots\n",
    "for i in range(df['data'].shape[1]):\n",
    "    xloc = ax[i,i].get_xlim()\n",
    "    yloc = ax[i,i].get_ylim()\n",
    "    ax[i, i].text(np.mean(xloc), np.mean(yloc), feat[i],\n",
    "                  horizontalalignment='center', verticalalignment='center', fontsize=16)\n",
    "    \n",
    "# hide x ticks for top plots\n",
    "plt.setp([a.get_xticklabels() for a in ax[0, :]], visible=False)\n",
    "\n",
    "# hide y ticks for right plots\n",
    "plt.setp([a.get_yticklabels() for a in ax[:, 1]], visible=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [0,2]\n",
    "X = df['data'][50:,idx]\n",
    "y = df['target'][50:]\n",
    "# scale y to be -1, 1\n",
    "y[y==1] = -1\n",
    "y[y==2] = 1\n",
    "feat = [df['feature_names'][x] for x in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cleanup():\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = linear_model.LogisticRegression()\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "f = plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(f)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = linear_model.LinearRegression()\n",
    "x0 = X[:,0].reshape([100,1])\n",
    "x1 = X[:,1].reshape([100,1])\n",
    "mdl = mdl.fit(x0, x1)\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()+0.2\n",
    "x0_max = X[:, 0].max()-0.2\n",
    "\n",
    "Z = mdl.predict([[x0_min], [x0_max]])\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# plot the line\n",
    "plt.plot([x0_min, x0_max], Z, 'k--', linewidth=3)\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "f = plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(f)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('{} = {:3.2f} * {} + {:3.1f}'.format(feat[1], mdl.coef_[0][0], feat[0], mdl.intercept_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = linear_model.LinearRegression()\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "f = plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(f)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = linear_model.LinearRegression()\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# round predictions\n",
    "Z[Z>=0] = 1\n",
    "Z[Z<0] = -1\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(cs)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit a decision tree\n",
    "mdl = tree.DecisionTreeClassifier(max_depth=1)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# round predictions\n",
    "Z[Z>=0] = 1\n",
    "Z[Z<0] = -1\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(cs)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the tree\n",
    "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
    "                         feature_names=feat, \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting a sinusoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a sample dataset of sinusoidal data\n",
    "rng = np.random.RandomState(777)\n",
    "N = 30\n",
    "\n",
    "# random points along the time axis for two cycles\n",
    "x = np.sort(2 * np.pi * rng.rand(N))\n",
    "y_true = np.sin(x)\n",
    "# generate the same data with random noise\n",
    "y_noise = np.sin(x) + (rng.rand(N)-0.5)*0.3\n",
    "\n",
    "# reshape x to be the only feature\n",
    "x = x.reshape(-1,1)\n",
    "\n",
    "# fit a decision tree\n",
    "mdl = tree.DecisionTreeRegressor(max_depth=5).fit(x, y_noise)\n",
    "\n",
    "# get test points\n",
    "x_test = np.linspace(0, 2*np.pi, 100).reshape(-1,1)\n",
    "y_test_pred = mdl.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "# plot original sinusoid\n",
    "plt.plot(x, y_true, 'k--',linewidth=2, label='Truth')\n",
    "\n",
    "# noisy test points\n",
    "plt.scatter(x, y_noise, marker='o', color='b', alpha=0.8, s=75, linewidth=2,label='Data')\n",
    "\n",
    "# decision tree decisions\n",
    "plt.plot(x_test, y_test_pred, 'r-', linewidth=2,label='Decision tree')\n",
    "\n",
    "plot_cleanup()\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.colorbar(f)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the tree\n",
    "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
    "                         feature_names=feat, \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "#plt.colorbar(cs)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best',max_depth=1)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the tree\n",
    "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
    "                         feature_names=feat, \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=1)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = mdl.predict(X_grid)\n",
    "\n",
    "# customize the prediction using the left side of above tree\n",
    "# apply:\n",
    "# petal length <= 3.9\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95)\n",
    "Z[idxUnk] = 0\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "plt.plot([4.95, 4.95],[x1_min, 4.75],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=1)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = mdl.predict(X_grid)\n",
    "\n",
    "# customize the prediction using the left side of above tree\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] <= 3.9)\n",
    "Z[idxUnk] = -1\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] > 3.9)\n",
    "Z[idxUnk] = 1\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "plt.plot([4.95, 4.95],[x1_min, 4.75],'k--',linewidth=3)\n",
    "plt.plot([x0_min, 4.95],[3.9, 3.9],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=1)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = mdl.predict(X_grid)\n",
    "Z = Z.astype(float)\n",
    "# customize the prediction using the left side of above tree\n",
    "# left side of tree\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] <= 3.9)\n",
    "Z[idxUnk] = -1\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] > 3.9)\n",
    "Z[idxUnk] = 1\n",
    "# right side of tree\n",
    "idxUnk = (X_grid[:,1] > 4.75) & (X_grid[:,1] <= 5.15)\n",
    "Z[idxUnk] = 0.5\n",
    "idxUnk = (X_grid[:,1] > 4.75) & (X_grid[:,1] > 5.15)\n",
    "Z[idxUnk] = 1\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "plt.plot([4.95, 4.95],[x1_min, 4.75],'k--',linewidth=3)\n",
    "plt.plot([x0_min, 4.95],[3.9, 3.9],'k--',linewidth=3)\n",
    "plt.plot([x0_min, x0_max],[5.15,5.15],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine a depth-3 tree\n",
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=3)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
    "                         feature_names=feat, \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=3)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "# get minimum and maximum values\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = mdl.predict(X_grid)\n",
    "Z = Z.astype(float)\n",
    "\n",
    "# customize the prediction using the left side of above tree\n",
    "# left side of tree\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] <= 3.9)\n",
    "Z[idxUnk] = -1\n",
    "idxUnk = (X_grid[:,1] <= 4.75) & (X_grid[:,0] <= 4.95) & (X_grid[:,1] > 3.9)\n",
    "Z[idxUnk] = 1\n",
    "# right side of tree\n",
    "idxUnk = (X_grid[:,1] > 4.75) & (X_grid[:,1] <= 5.15) & (X_grid[:,0] <= 6.6)\n",
    "Z[idxUnk] = 0.85\n",
    "idxUnk = (X_grid[:,1] > 4.75) & (X_grid[:,1] <= 5.15) & (X_grid[:,0] > 6.6)\n",
    "Z[idxUnk] = -0.6\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the contour - colouring different regions\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "\n",
    "plt.plot([x0_min, x0_max],[4.75,4.75],'k--',linewidth=3)\n",
    "plt.plot([4.95, 4.95],[x1_min, 4.75],'k--',linewidth=3)\n",
    "plt.plot([x0_min, 4.95],[3.9, 3.9],'k--',linewidth=3)\n",
    "plt.plot([x0_min, x0_max],[5.15,5.15],'k--',linewidth=3)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algorithm at different spots in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best',max_depth=3).fit(X,y)\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "plot_model_pred_2d(mdl, X, y, feat, plot_colorbar=False)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine a depth-7 tree\n",
    "mdl = tree.DecisionTreeClassifier(criterion='entropy', splitter='best',max_depth=7).fit(X,y)\n",
    "tree_graph = tree.export_graphviz(mdl, out_file=None,\n",
    "                         feature_names=feat, \n",
    "                         filled=True, rounded=True)  \n",
    "graph = pydotplus.graphviz.graph_from_dot_data(tree_graph) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "plot_model_pred_2d(mdl, X, y, feat, plot_colorbar=False)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bootstrapping CDF vs. PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create some test data\n",
    "dx = .1\n",
    "X  = np.arange(-2,2,dx)\n",
    "Y  = np.exp(-X**2)\n",
    "\n",
    "# Normalize the data to a proper PDF\n",
    "Y /= (dx*Y).sum()\n",
    "\n",
    "# Compute the CDF\n",
    "CY = np.cumsum(Y*dx)\n",
    "\n",
    "# shift the axis over, set the histogram widths\n",
    "factor = 10\n",
    "X = (X*factor)+70\n",
    "hist_w = 1\n",
    "\n",
    "colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "plt.figure(figsize=[12,7])\n",
    "# plot pdf\n",
    "plt.plot(X,Y, linewidth=3, color=colors[1])\n",
    "# plot hist\n",
    "plt.bar(X-(dx*factor/2.),Y,width=dx*factor,linewidth=0.1, facecolor=colors[1],alpha=0.5)\n",
    "# plot CDF\n",
    "plt.plot(X,CY,'--', linewidth=3,color=colors[3])\n",
    "\n",
    "plot_cleanup()\n",
    "plt.show()\n",
    "\n",
    "# no histogram\n",
    "\n",
    "\n",
    "# Create some test data\n",
    "dx = .1\n",
    "X  = np.arange(-2,2,dx)\n",
    "Y  = np.exp(-X**2)\n",
    "\n",
    "# Normalize the data to a proper PDF\n",
    "Y /= (dx*Y).sum()\n",
    "\n",
    "# Compute the CDF\n",
    "CY = np.cumsum(Y*dx)\n",
    "\n",
    "# shift the axis over, set the histogram widths\n",
    "factor = 10\n",
    "X = (X*factor)+70\n",
    "hist_w = 1\n",
    "\n",
    "colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "plt.figure(figsize=[12,7])\n",
    "# plot pdf\n",
    "plt.plot(X,Y, linewidth=3, color=colors[1])\n",
    "# plot CDF\n",
    "plt.plot(X,CY,'--', linewidth=3,color=colors[3])\n",
    "\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "\n",
    "# a sample of data using rand + normrnd\n",
    "np.random.seed(123)\n",
    "Y = np.random.normal(loc=0.0, scale=1.0, size=[50,])\n",
    "plt.figure(figsize=[12,7])\n",
    "n, bins, patches = plt.hist(Y,bins=np.linspace(-5,5,50),color=colors[1],normed=True)\n",
    "\n",
    "\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "# reset xticks to be in the \"weight\" range\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks( locs, [x*factor+70 for x in locs] )\n",
    "\n",
    "plot_cleanup()\n",
    "plt.show()\n",
    "\n",
    "# plot the CDF of the above\n",
    "plt.figure(figsize=[12,7])\n",
    "\n",
    "n, bins, patches = plt.hist(Y,bins=np.linspace(-5,5,50),color=colors[1],normed=True)\n",
    "n, bins, patches = plt.hist(Y,bins=np.linspace(-5,5,50),color=colors[2],normed=True,\n",
    "                            linewidth=4,histtype='step',cumulative=True)\n",
    "\n",
    "\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "# reset xticks to be in the \"weight\" range\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks( locs, [x*factor+70 for x in locs] )\n",
    "\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create some test data\n",
    "hist_w = 1\n",
    "\n",
    "dx = .1\n",
    "X  = np.arange(-3,3,dx)\n",
    "Y  = np.exp(-X**2)\n",
    "\n",
    "# Normalize the data to a proper PDF\n",
    "Y /= (dx*Y).sum()\n",
    "\n",
    "# Compute the CDF\n",
    "CY = np.cumsum(Y*dx)\n",
    "colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "\n",
    "# a sample of data using rand + normrnd\n",
    "np.random.seed(123)\n",
    "Y = np.random.normal(loc=0.0, scale=1.0, size=[50,])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "plt.figure(figsize=[12,7])\n",
    "\n",
    "\n",
    "# plot CDF\n",
    "n, bins, patches = plt.hist(Y,bins=np.linspace(-5,5,50),color=colors[2],normed=True,\n",
    "                            linewidth=4,histtype='step',cumulative=True)\n",
    "plt.plot(X,CY,'--', linewidth=3,color=colors[3])\n",
    "\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "# reset xticks to be in the \"weight\" range\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks( locs, [int(x*factor+70) for x in locs] )\n",
    "\n",
    "plot_cleanup()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a sample of data using rand + normrnd\n",
    "for m in range(5):\n",
    "    np.random.seed(123)\n",
    "    Y = np.random.normal(loc=0.0, scale=1.0, size=[50,])\n",
    "\n",
    "    colors = plt.cm.Set1([x/7.0 for x in range(7)])\n",
    "    plt.figure(figsize=[12,7])\n",
    "\n",
    "    # plot original CDF\n",
    "    n, bins, patches = plt.hist(Y,bins=np.linspace(-5,5,50),color=colors[2],normed=True,\n",
    "                                linewidth=4,histtype='step',cumulative=True)\n",
    "\n",
    "    # remove green from our colors\n",
    "    colors = [colors[i] for i in range(colors.shape[0]) if i!=2]\n",
    "\n",
    "    # plot ~5 repeated samples\n",
    "    for i in range(m):\n",
    "        # bootstrap sample\n",
    "        idx = np.random.randint(0, high=Y.shape[0],size=Y.shape[0])\n",
    "        n, bins, patches = plt.hist(Y[idx],bins=np.linspace(-5,5,50),color=colors[i],normed=True,\n",
    "                                    linewidth=0.1,histtype='bar',cumulative=False,alpha=0.5)\n",
    "        n, bins, patches = plt.hist(Y[idx],bins=np.linspace(-5,5,50),color=colors[i],normed=True,\n",
    "                                    linewidth=2,histtype='step',cumulative=True)\n",
    "\n",
    "    plt.xlim([-3,3])\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "    # reset xticks to be in the \"weight\" range\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks( locs, [int(x*factor+70) for x in locs] )\n",
    "\n",
    "    plot_cleanup()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load fisher-iris and build bagging model .. showing each individual tree and cumulative result\n",
    "# real example\n",
    "df = datasets.load_iris()\n",
    "\n",
    "idx = [0,2]\n",
    "X = df['data'][50:,idx]\n",
    "y = df['target'][50:]\n",
    "\n",
    "feat = [df['feature_names'][x] for x in idx]\n",
    "\n",
    "# get minimum and maximum values for dataset\n",
    "# these are used in the plotting\n",
    "x0_min = X[:, 0].min()\n",
    "x0_max = X[:, 0].max()\n",
    "x1_min = X[:, 1].min()\n",
    "x1_max = X[:, 1].max()\n",
    "\n",
    "vmin = np.min([x0_min,x1_min])\n",
    "vmax = np.max([x0_max,x1_max])\n",
    "xx, yy = np.meshgrid(np.linspace(x0_min, x0_max, 1000),\n",
    "                     np.linspace(x1_min, x1_max, 1000))\n",
    "\n",
    "\n",
    "# plot the original data\n",
    "fig = plt.figure(figsize=[8,5])\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, marker='o',\n",
    "            s=60, cmap=cm)\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "# disable ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(321)\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "mdls = list()\n",
    "ypred = np.zeros([y.shape[0]])\n",
    "\n",
    "for i in range(5):\n",
    "    fig = plt.figure(figsize=[8,5])\n",
    "    \n",
    "    # random sample\n",
    "    idx = np.random.randint(0, X.shape[0], X.shape[0])\n",
    "    idxOOB = [x for x in range(X.shape[0]) if x not in idx]\n",
    "    \n",
    "    # create the estimator\n",
    "    mdl = clf.fit(X[idx,:],y[idx])\n",
    "    mdls.append(mdl)    \n",
    "\n",
    "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    if i==0:\n",
    "        Z_all = Z.astype(float)\n",
    "    else:\n",
    "        Z_all += Z.astype(float)\n",
    "    \n",
    "    # plot the contour - colouring different regions according to class\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "    # plot the individual data points - colouring by the *true* outcome\n",
    "    color = np.asarray(y[idx].ravel(),dtype='float')\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color, edgecolor='k',\n",
    "                marker='o', linewidth=2,\n",
    "                s=60, cmap=cm)\n",
    "    \n",
    "    # plot \"s\" for data points which weren't included\n",
    "    color = np.asarray(y[idxOOB].ravel(),dtype='float')\n",
    "    plt.scatter(X[idxOOB, 0], X[idxOOB, 1], c=color, edgecolor='gray',\n",
    "                marker='s', linewidth=2,\n",
    "                s=60, cmap=cm)\n",
    "\n",
    "    plt.xlabel(feat[0],fontsize=24)\n",
    "    plt.ylabel(feat[1],fontsize=24)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    #plt.colorbar(cs)\n",
    "\n",
    "    # cleanup plot\n",
    "    plot_cleanup()\n",
    "\n",
    "    # disable ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    txt = 'Tree {}'.format(i+1)\n",
    "    plt.text(7.0, 3.5, txt, fontdict={'fontsize':12})\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "print('Final aggregation')\n",
    "Z_all = Z_all / 5.0\n",
    "Z_all = np.round(Z_all)\n",
    "\n",
    "fig = plt.figure(figsize=[8,5])\n",
    "# plot the contour - colouring different regions according to class\n",
    "cs = plt.contourf(xx, yy, Z_all, cmap=cm)\n",
    "\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y.ravel(),dtype='float')\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=color, edgecolor='k',\n",
    "            marker='o', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "\n",
    "plt.xlabel(feat[0],fontsize=24)\n",
    "plt.ylabel(feat[1],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "\n",
    "#plt.colorbar(cs)\n",
    "\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "\n",
    "# disable ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "txt = 'All trees'\n",
    "plt.text(7.0, 3.5, txt, fontdict={'fontsize':12})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load fisher-iris and build bagging model .. showing each individual tree and cumulative result\n",
    "# real example\n",
    "df = datasets.load_iris()\n",
    "\n",
    "idx = [0,2]\n",
    "X = df['data'][50:,:]\n",
    "y = df['target'][50:]\n",
    "\n",
    "feat = df['feature_names']\n",
    "\n",
    "# get minimum and maximum values for dataset\n",
    "# these are used in the plotting\n",
    "x_min = 0\n",
    "x_max = 8\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 1000),\n",
    "                     np.linspace(x_min, x_max, 1000))\n",
    "\n",
    "\n",
    "np.random.seed(321)\n",
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "mdls = list()\n",
    "fig = plt.figure(figsize=[14,10])\n",
    "\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(2,3,i+1)\n",
    "    \n",
    "    # random sample of data\n",
    "    idx = np.random.randint(0, X.shape[0], X.shape[0])\n",
    "    idxOOB = [x for x in range(X.shape[0]) if x not in idx]\n",
    "    \n",
    "    # random subset of features\n",
    "    idxFeat = np.random.permutation(4)[:2]\n",
    "    \n",
    "    # create the estimator\n",
    "    mdl = clf.fit(X[idx,:][:,idxFeat],y[idx])\n",
    "    mdls.append(mdl)    \n",
    "\n",
    "    Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # plot the contour - colouring different regions according to class\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "\n",
    "    # plot the individual data points - colouring by the *true* outcome\n",
    "    color = np.asarray(y[idx].ravel(),dtype='float')\n",
    "    plt.scatter(X[idx, idxFeat[0]], X[idx, idxFeat[1]], c=color, marker='o', edgecolors='k',\n",
    "                s=60, cmap=cm)\n",
    "    \n",
    "    # plot a gray square around for data points which weren't included\n",
    "    color = np.asarray(y[idxOOB].ravel(),dtype='float')\n",
    "    plt.scatter(X[idxOOB, idxFeat[0]], X[idxOOB, idxFeat[1]], c=color, marker='s',\n",
    "                linewidth=2, edgecolors='gray',\n",
    "                s=60, cmap=cm)\n",
    "    \n",
    "\n",
    "    plt.xlabel(feat[idxFeat[0]],fontsize=24)\n",
    "    plt.ylabel(feat[idxFeat[1]],fontsize=24)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    #plt.colorbar(cs)\n",
    "\n",
    "    # cleanup plot\n",
    "    plot_cleanup()\n",
    "\n",
    "    # disable ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    txt = 'Tree {}'.format(i+1)\n",
    "    plt.text(3.0, 4.0, txt, fontdict={'fontsize':12,'fontweight':'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load fisher-iris and build bagging model .. showing each individual tree and cumulative result\n",
    "# real example\n",
    "df = datasets.load_iris()\n",
    "\n",
    "idx = [0,2]\n",
    "X = df['data'][50:,:]\n",
    "y = df['target'][50:]\n",
    "\n",
    "feat = df['feature_names']\n",
    "\n",
    "# get minimum and maximum values for dataset\n",
    "# these are used in the plotting\n",
    "x_min = 0\n",
    "x_max = 8\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 1000),\n",
    "                     np.linspace(x_min, x_max, 1000))\n",
    "\n",
    "\n",
    "np.random.seed(172631)\n",
    "i=0\n",
    "# random sample of data\n",
    "idx = np.random.randint(0, X.shape[0], X.shape[0])\n",
    "idxOOB = [x for x in range(X.shape[0]) if x not in idx]\n",
    "\n",
    "# random subset of features\n",
    "idxFeat = np.random.permutation(4)[:2]\n",
    "\n",
    "# create the estimator\n",
    "mdl = clf.fit(X[idx,:][:,idxFeat],y[idx])\n",
    "mdls.append(mdl)    \n",
    "\n",
    "Z = mdl.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plot the bootstrap sample with the OOB observations\n",
    "fig = plt.figure(figsize=[14,10])\n",
    "# plot the individual data points - colouring by the *true* outcome\n",
    "color = np.asarray(y[idx].ravel(),dtype='float')\n",
    "plt.scatter(X[idx, idxFeat[0]], X[idx, idxFeat[1]], c=color, marker='o',\n",
    "            edgecolor='k', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "# plot \"x\" for data points which weren't included\n",
    "color = np.asarray(y[idxOOB].ravel(),dtype='float')\n",
    "plt.scatter(X[idxOOB, idxFeat[0]], X[idxOOB, idxFeat[1]], c=color, marker='s',\n",
    "            linewidth=2, edgecolors='gray',\n",
    "            s=60, cmap=cm)\n",
    "plt.xlabel(feat[idxFeat[0]],fontsize=24)\n",
    "plt.ylabel(feat[idxFeat[1]],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.xlim([0,8])\n",
    "plt.ylim([0,8])\n",
    "plt.show()\n",
    "\n",
    "# plot the bootstrap sample w/o OOB\n",
    "fig = plt.figure(figsize=[14,10])\n",
    "color = np.asarray(y[idx].ravel(),dtype='float')\n",
    "plt.scatter(X[idx, idxFeat[0]], X[idx, idxFeat[1]], c=color, marker='o',\n",
    "            linewidth=2, edgecolor='k',\n",
    "            s=60, cmap=cm)\n",
    "plt.xlabel(feat[idxFeat[0]],fontsize=24)\n",
    "plt.ylabel(feat[idxFeat[1]],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "#plt.text(3.0, 4.0, txt, fontdict={'fontsize':12,'fontweight':'bold'})\n",
    "plt.xlim([0,8])\n",
    "plt.ylim([0,8])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plot the bootstrap sample w/o OOB and with decision surface\n",
    "fig = plt.figure(figsize=[14,10])\n",
    "cs = plt.contourf(xx, yy, Z, cmap=cm)\n",
    "color = np.asarray(y[idx].ravel(),dtype='float')\n",
    "plt.scatter(X[idx, idxFeat[0]], X[idx, idxFeat[1]], c=color, marker='o',\n",
    "            edgecolor='k', linewidth=2,\n",
    "            s=60, cmap=cm)\n",
    "plt.xlabel(feat[idxFeat[0]],fontsize=24)\n",
    "plt.ylabel(feat[idxFeat[1]],fontsize=24)\n",
    "plt.axis(\"tight\")\n",
    "# cleanup plot\n",
    "plot_cleanup()\n",
    "plt.grid()\n",
    "#plt.text(3.0, 4.0, txt, fontdict={'fontsize':12,'fontweight':'bold'})\n",
    "plt.xlim([0,8])\n",
    "plt.ylim([0,8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance curve of random forest\n",
    "\n",
    "## on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "\n",
    "np.random.seed(321)\n",
    "mdl = ensemble.RandomForestClassifier(n_estimators=50, oob_score=True)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "\n",
    "err = list()\n",
    "n_samples = X.shape[0]\n",
    "pred = np.zeros([y.shape[0],50])\n",
    "roll_pred = np.zeros([y.shape[0],50])\n",
    "\n",
    "idx = np.zeros([y.shape[0],50],dtype=bool)\n",
    "for i, estimator in enumerate(mdl.estimators_):\n",
    "    # Here at each iteration we obtain out of bag samples for every tree.\n",
    "    idxOOB = _generate_unsampled_indices(estimator.random_state, n_samples)\n",
    "    \n",
    "    # update predictions\n",
    "    curr_pred = estimator.predict(X[idxOOB,:])\n",
    "    pred[idxOOB,i] = curr_pred\n",
    "    idx[idxOOB,i] = True\n",
    "\n",
    "    idxFeat = range(i+1)\n",
    "    roll_pred[:,i] = np.sum(pred[:,idxFeat]*idx[:,idxFeat],axis=1)\n",
    "    idxKeep = np.sum(idx[:, idxFeat],axis=1)\n",
    "    \n",
    "    roll_pred[idxKeep>0,i] = roll_pred[idxKeep>0,i] / idxKeep[idxKeep>0]\n",
    "    \n",
    "    # convert from 0/1 to the class labels\n",
    "    roll_pred[idxKeep>0,i] = mdl.classes_[np.round(roll_pred[idxKeep>0,i]).astype(int)]\n",
    "    \n",
    "    \n",
    "    # calculate current error\n",
    "    err.append( 1.0-np.mean(roll_pred[idxKeep>0,i] == y[idxKeep>0] ) )\n",
    "\n",
    "err = np.asarray(err)\n",
    "plt.figure(figsize=[10,7])\n",
    "plt.plot(range(err.shape[0]),err*100.0,color=colors[1],linewidth=4)\n",
    "plt.ylabel('Number of errors',fontsize=20)\n",
    "plt.xlabel('Number of trees',fontsize=20)\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = datasets.load_iris()\n",
    "\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "\n",
    "np.random.seed(321)\n",
    "mdl = ensemble.RandomForestClassifier(n_estimators=50, oob_score=True)\n",
    "mdl = mdl.fit(X,y)\n",
    "\n",
    "from sklearn.ensemble.forest import _generate_unsampled_indices\n",
    "\n",
    "err = list()\n",
    "n_samples = X.shape[0]\n",
    "pred = np.zeros([y.shape[0],50])\n",
    "roll_pred = np.zeros([y.shape[0],50])\n",
    "idx = np.zeros([y.shape[0],50],dtype=bool)\n",
    "for i, estimator in enumerate(mdl.estimators_):\n",
    "    # Here at each iteration we obtain out of bag samples for every tree.\n",
    "    idxOOB = _generate_unsampled_indices(estimator.random_state, n_samples)\n",
    "    \n",
    "    # update predictions\n",
    "    curr_pred = estimator.predict(X[idxOOB,:])\n",
    "    pred[idxOOB,i] = curr_pred\n",
    "    idx[idxOOB,i] = True\n",
    "\n",
    "    idxFeat = range(i+1)\n",
    "    roll_pred[:,i] = np.sum(pred[:,idxFeat]*idx[:,idxFeat],axis=1)\n",
    "    idxKeep = np.sum(idx[:, idxFeat],axis=1)\n",
    "    \n",
    "    roll_pred[idxKeep>0,i] = roll_pred[idxKeep>0,i] / idxKeep[idxKeep>0]\n",
    "    \n",
    "    # convert from 0/1 to the class labels\n",
    "    roll_pred[idxKeep>0,i] = mdl.classes_[np.round(roll_pred[idxKeep>0,i]).astype(int)]\n",
    "    # calculate current error\n",
    "    err.append( 1.0-np.mean(roll_pred[idxKeep>0,i] == y[idxKeep>0] ) )\n",
    "\n",
    "err = np.asarray(err)\n",
    "plt.figure(figsize=[10,7])\n",
    "plt.plot(range(err.shape[0]),err*100.0,color=colors[1],linewidth=4)\n",
    "plt.ylabel('Number of errors',fontsize=20)\n",
    "plt.xlabel('Number of trees',fontsize=20)\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = mdl.feature_importances_\n",
    "std = np.std([current_tree.feature_importances_ for current_tree in mdl.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=[10,7])\n",
    "plt.barh(range(X.shape[1]), importances[indices],\n",
    "       color=colors[0], xerr=std[indices], align=\"center\")\n",
    "plt.yticks(range(X.shape[1]), [feat[i] for i in indices])\n",
    "plt.ylim([-1, X.shape[1]])\n",
    "plot_cleanup()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
